# -*- coding: utf-8 -*-
"""Medium A4 - Scatter plot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VIpc1_YquuOh-SdOCDShyxHZZ11Dyx5H
"""

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

df = pd.read_csv('/content/customer_shopping_data.csv')

# transforming age, gender, and category columns so they can be used as feature variables
df_transformed = df.copy()

# creating age groups with a range of 3 years
df_transformed['age_range'] = pd.cut(df_transformed['age'], range(18, 70, 7), right=False)

# creating dummy variables for age 
age_groups = pd.get_dummies(df_transformed['age_range'], prefix='age')
df_transformed = pd.concat([df_transformed, age_groups], axis=1)
df_transformed.drop(['age', 'age_range'], axis=1, inplace=True)

# creating dummy variables for gender
gender_groups = pd.get_dummies(df_transformed, columns=['gender'], prefix='gender')
df_transformed = pd.concat([df_transformed, gender_groups], axis=1)
df_transformed.drop('gender', axis=1, inplace=True)

# repeating process for categories variable
categories = pd.get_dummies(df_transformed['category'], prefix='category')
df_transformed = pd.concat([df_transformed, categories], axis=1)
df_transformed.drop('category', axis=1, inplace=True)

# dropping columns that are not needed
df_transformed.drop(['invoice_no', 'customer_id', 'quantity', 'price',
                     'payment_method', 'invoice_date',
                     'shopping_mall'], axis=1, inplace=True)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(df_transformed)

# using the elbow method to determine the optimal number of clusters
inertia = []
for k in range(1, 11):
    kmeans_model = KMeans(n_clusters=k, n_init=10, random_state=42)
    kmeans_model.fit(X_scaled)
    inertia.append(kmeans_model.inertia_)

# plot the elbow curve
plt.plot(range(1, 11), inertia)
plt.xlabel('Number of clusters')
plt.ylabel('Inertia')
plt.title('Elbow Curve')
plt.show()

# select the optimal number of clusters based on the elbow curve

# preparing data to be plotted and represented as clusters
#scaler = StandardScaler()
#X_scaled = scaler.fit_transform(df_transformed)
kmeans_model = KMeans(n_clusters=5, n_init=10, random_state=42)
kmeans_model.fit(X_scaled)
labels = kmeans_model.predict(X_scaled)

# reducing dimensionality to 2 dimensions using PCA 
pca = PCA(n_components=2)
X = pca.fit_transform(X_scaled)

# plotting the clusters
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
plt.title('KMeans Scatter Plot')
plt.show()

# prepping data for analysis 
df_transformed['cluster'] = labels
grouped = df_transformed.groupby('cluster').mean()

grouped = grouped.T.drop_duplicates().T

print(grouped)

for i in range(len(grouped)):
    print(f"\nCluster {i}:")
    cluster_data = grouped.iloc[i]
    top_features = cluster_data.nlargest(5)
    print(top_features)